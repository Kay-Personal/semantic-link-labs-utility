{"cells":[{"cell_type":"markdown","source":["### Install the latest .whl package\n","\n","Check [here](https://pypi.org/project/semantic-link-labs/) to see the latest version."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5c27dfd1-4fe0-4a97-92e6-ddf78889aa93"},{"cell_type":"code","source":["%pip uninstall \"builtin/semantic_link_labs-0.9.4-py3-none-any.whl\" -y"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fd5a1a69-8fc3-4fc3-a625-650371506c7d"},{"cell_type":"code","source":["# %pip install semantic-link-labs\n","\n","%pip install \"builtin/semantic_link_labs-0.9.4-py3-none-any.whl\""],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d5cae9db-cef9-48a8-a351-9c5fcc99645c"},{"cell_type":"markdown","source":["### Requirements\n","* Fabric Capacity with XMLA read/write enabled\n","    * A Fabric Trial Capacity is sufficient for evaluation.\n","    * The XMLA Endpoint must be read/write enabled because the perf lab provisions semantic models automatically.\n","* Fabric Permissions\n","    * User must have permissions to create workspaces, lakehouses, and semantic models. This notebook provisions sample resources to demonstrate the use of a perf lab.\n","    * User should have access to a Fabric capacity. This notebook provisions workspaces, lakehouses, and semantic models on a Fabric capacity.\n","    * Connect this notebook to a lakehouse without a schema to persist test definitions and test results. Although strictly not a requirement, it eliminates the need to provide the name and Id of a disconnected lakehouse.\n","\n","### Result\n","* A master and test workspaces, lakehouses, and semantic models are created to establish a perf lab\n","    * The master workspace contains a lakehouse and a sample semantic model in Direct Lake on OneLake mode that uses the lakehouse as its data source. \n","    * The test workspace contains semantic models cloned from the sample semantic model in the master workspace.\n","    * Various Delta tables are created in the lakehouse connected to this notebook to persist test definitions, table analysis, and test results.\n","    * The resources in the master workspace and in the test workspace are deprovisioned upon completion of the perf lab. Delete the workspaces manually.\n","* The names of the newly created resources can be adjusted to customize the perf lab.\n"],"metadata":{},"id":"2856d26d"},{"cell_type":"markdown","source":["### Import the library and set global notebook parameters\n","\n","This notebook deploys lakehouses and semantic models across different workspaces, but the resources can also be hosted together in a centralized workspace. The master workspace contains a lakehouse with sample data, used as the data source for the sample semantic models in Direct Lake on OneLake mode. The master semantic model serves as a template for the actual test models, which this notebook provisions prior to running the performance tests by cloning the master semantic model."],"metadata":{},"id":"b195eae8"},{"cell_type":"code","source":["\n","import sempy_labs.perf_lab as perf_lab\n","\n","master_workspace = 'Perf Lab Master'                # Enter the name of the master workspace.\n","lakehouse = 'SalesSampleLakehouse'                        # Enter the name of the lakehouse used as the data source.\n","master_dataset = 'Master Semantic Model'            # Enter the name of the master semantic model.\n","\n","test_workspace = 'Perf Lab Testing'                 # Enter the name of the workspace for the semantic model clone.\n","target_dataset_prefix = 'Test Model_'               # Enter the common part of the name for all semantic model clones.\n","test_dataset_A = target_dataset_prefix + 'A'        # Enter the name of the first semantic model clone.\n","test_dataset_B = target_dataset_prefix + 'B'        # Enter the name of the second semantic model clone.\n","\n","capacity_id = None                                  # The Id of the capacity for the workspaces. \n","                                                    # Leave this as None to use the capacity of the attached lakehouse or perf lab notebook.\n","                                        \n","test_definitions_tbl = 'TestDefinitions'            # The name of the table in the notebook-attached lakehouse to store the test definitions.\n","column_segments_tbl = 'StorageTableColumnSegments'  # The name of the table in the notebook-attached lakehouse to store the test definitions.\n","trace_events_tbl = \"TraceEvents\"                    # The name of the table in the notebook-attached lakehouse to store the captured trace events.\n","\n","execution_log = \"ExecutionLog\"                      # The name of the table in the notebook-attached lakehouse to store the test cycle execution details."],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1344e286"},{"cell_type":"markdown","source":["### Working with test definitions\n","\n","Test definitions define the key parameters for the test runs, including the following fields: QueryId, QueryText, MasterWorkspace, MasterDataset, TargetWorkspace, TargetDataset, DatasourceName, DatasourceWorkspace, DatasourceType. The following test code illustrates how to work with the TestDefinition and TestSuite classes.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f634c948-7c23-4d6d-af35-f1f9acdc4dd2"},{"cell_type":"code","source":["first_test_definition = perf_lab.TestDefinition(QueryId=1, QueryText=\"Evaluate {1}\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                   TargetWorkspace=test_workspace, TargetDataset='Test Model_', DatasourceName=lakehouse,\n","                   DatasourceWorkspace=master_workspace, DatasourceType=\"WrongType\")\n","\n","first_test_definition.remove(\"DatasourceType\")\n","print(first_test_definition.get_keys())\n","first_test_definition.add(\"DatasourceType\", \"Lakehouse\")\n","first_test_definition.TargetDataset='Test Model_A'\n","print(first_test_definition.get_keys())\n","print(first_test_definition.get_values())\n","print(first_test_definition.to_schema())\n","\n","test_definitions = [\n","    first_test_definition,\n","    perf_lab.TestDefinition(QueryId=2, QueryText=\"Evaluate {2}\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                   TargetWorkspace=test_workspace, TargetDataset='Test Model_B', DatasourceName=lakehouse,\n","                   DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","]\n","\n","test_suite = perf_lab.TestSuite(test_definitions)\n","test_suite.save_as(test_definitions_tbl)\n","display(test_suite.to_df())\n","\n","test_suite.remove_test_definition(first_test_definition)\n","display(test_suite.to_df())\n","\n","test_suite.clear()\n","test_suite.load(test_definitions_tbl)\n","display(test_suite.to_df())\n","\n","test_suite.add_test_definition(\n","    perf_lab.TestDefinition(QueryId=3, QueryText=\"Evaluate {3}\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                   TargetWorkspace=test_workspace, TargetDataset='Test Model_C', DatasourceName=lakehouse,\n","                   DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n",")\n","display(test_suite.to_df())\n","\n","test_suite.add_field(\"AdditionalProperty\", \"additional value\")\n","print(test_suite.get_schema())\n","\n","test_suite.remove_field(\"AdditionalProperty\")\n","print(test_suite.get_schema())\n","\n","test_suite.clear()\n","display(test_suite.to_df())\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"651c6feb-810a-4856-91c2-7591916df5d3"},{"cell_type":"code","source":["\n","test_suite = perf_lab.SalesSampleQueries().to_test_suite(\n","    target_dataset = test_dataset_A,\n","    target_workspace = test_workspace,\n","    master_dataset = master_dataset,\n","    master_workspace = master_workspace,\n","    data_source = lakehouse,\n","    data_source_workspace = master_workspace,   \n",")\n","\n","display(test_suite.to_df())"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"894a139a-f347-49d8-bbd3-b4541532a2e7"},{"cell_type":"markdown","source":["### Run default (incremental), cold, and warm query tests\n","The main purpose of a test run is to measure the performance of a set of DAX queries against the test semantic models with different memory states: Cold (full framing), Semi-warm (incremental framing), and Warm (no framing). Other than running the queries and measuring response times, the run_test_cycle() function must therefore perform additional actions, specifically clearing the cache and refreshing the model."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ecf9fff6-8c02-4e64-9bbc-fe055bcd357b"},{"cell_type":"code","source":["with perf_lab.ExecutionTracker(\n","    table_name = execution_log,\n","    description=\"Running a test cycle.\") as tracker:\n","\n","    test_suite = perf_lab.TestSuite(\n","        [\n","        perf_lab.TestDefinition(QueryId=\"TestQuery\", QueryText=\"EVALUATE SUMMARIZECOLUMNS(\\\"Test\\\", \\\"Hello World\\\")\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                    TargetWorkspace=test_workspace, TargetDataset=test_dataset_A, DatasourceName=lakehouse,\n","                    DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","        ]\n","    )\n","\n","    test_suite = perf_lab.initialize_test_cycle(\n","        test_suite = test_suite, \n","        test_run_id = tracker.run_id,\n","        test_description = \"This run is for test purposes.\"\n","    )\n","\n","    inc_results = perf_lab.run_test_cycle(\n","        test_suite = test_suite,\n","        clear_query_cache = True,\n","        refresh_type = \"clearValuesFull\",\n","        tag = \"testing only\"\n","        )\n","\n","    display(inc_results[0])\n","    display(inc_results[1])"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f9e558fd-b9e0-4971-bdec-f4d01a228319"},{"cell_type":"markdown","source":["### Provision master workspace, lakehouse, and semantic model with sample data\n","A sample lakehouse can be provisioned by calling the provision_sample_lakehouse() function with a table-generator function as an input parameter to customize the table generation. A sample semantic model can be provisioned by calling the function with a metadata-generator function as an input parameter to customize the semantic model generation."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"50faa5e0-26d9-4f97-a8cd-76a0d96ce267"},{"cell_type":"code","source":["# Can use a test suite to supply the workspace and lakehouse names.\n","test_suite = perf_lab.TestSuite(\n","    [\n","    perf_lab.TestDefinition(QueryId=\"TestQuery\", QueryText=\"EVALUATE SUMMARIZECOLUMNS(\\\"Test\\\", \\\"Hello World\\\")\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                TargetWorkspace=test_workspace, TargetDataset=test_dataset_A, DatasourceName=lakehouse,\n","                DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","    ])\n","\n","# TableGeneratorCallback = Callable[[UUID, UUID, dict], None]\n","def noop(\n","    workspace_id,\n","    lakehouse_id,\n","    table_properties,\n","):\n","    return None\n","\n","id_pairs = perf_lab.provision_lakehouses(\n","    test_suite = test_suite,\n","    table_properties={},\n","    table_generator=noop,\n","    capacity = capacity_id\n",")\n","\n","print(id_pairs)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"59d43593-ff70-467d-84a0-1076b7b9670a"},{"cell_type":"code","source":["# Can use a test suite to supply the dataset, workspace, and lakehouse names.\n","test_suite = perf_lab.TestSuite(\n","    [\n","    perf_lab.TestDefinition(QueryId=\"TestQuery\", QueryText=\"EVALUATE SUMMARIZECOLUMNS(\\\"Test\\\", \\\"Hello World\\\")\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                TargetWorkspace=test_workspace, TargetDataset=test_dataset_A, DatasourceName=lakehouse,\n","                DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","    ])\n","\n","# MetadataGeneratorCallback = Callable[[str, UUID, bool], None]\n","def no_metadata(\n","    semantic_model,\n","    workspace,\n","    remove_schema,\n","):\n","    return None\n","\n","name_id_pairs = perf_lab.provision_master_semantic_models(\n","    test_suite = test_suite,\n","    semantic_model_mode = \"OneLake\",\n","    overwrite = True,\n","    metadata_generator = no_metadata,\n","    )\n","\n","print(name_id_pairs)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"505ece27-6b85-4767-8826-dece14392ecb"},{"cell_type":"code","source":["# Can also provision lakehouses and semantic models individually without the help of a test suite.\n","\n","# TableGeneratorCallback = Callable[[UUID, UUID, dict], None]\n","def create_people_table(\n","    workspace_id,\n","    lakehouse_id,\n","    table_properties,\n","):\n","    import pandas as pd\n","    from sempy_labs._helper_functions import save_as_delta_table\n","    \n","    data = {\n","        \"name\": [\"Alice\", \"Bob\", \"Cathy\"],\n","        \"age\": [30, 25, 27]\n","        }\n","\n","    save_as_delta_table(\n","        dataframe = pd.DataFrame(data),\n","        delta_table_name = \"People\",\n","        write_mode = 'overwrite',\n","        lakehouse = lakehouse_id,\n","        workspace = workspace_id,\n","        )\n","    return None\n","\n","(master_workspace_id, lakehouse_id) = perf_lab.provision_lakehouse(\n","    workspace = master_workspace, \n","    lakehouse = lakehouse,\n","    table_properties={},\n","    table_generator=create_people_table,\n","    capacity = capacity_id\n",") \n","\n","print((master_workspace_id, lakehouse_id))\n","\n","# MetadataGeneratorCallback = Callable[[str, UUID, bool], None]\n","def no_metadata(\n","    semantic_model,\n","    workspace,\n","    remove_shema,\n","):\n","    return None\n","\n","(master_dataset_name, master_dataset_id) = perf_lab.provision_semantic_model(\n","    workspace = master_workspace_id, \n","    lakehouse=lakehouse_id, \n","    semantic_model_name = master_dataset,\n","    semantic_model_mode = \"OneLake\",\n","    overwrite = True,\n","    metadata_generator = no_metadata,\n","    )\n","\n","print((master_dataset_name, master_dataset_id))"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"93b5005f-15e0-4174-b38b-6f3ecdfd625c"},{"cell_type":"code","source":["# Provision a sales sample lakehouse.\n","sslh_config = perf_lab.SalesLakehouseConfig(start_date=\"2025-01-25\", years=5, fact_rows_in_millions=10)\n","print(sslh_config.to_dict())\n","\n","(master_workspace_id, lakehouse_id) = perf_lab.provision_lakehouse(\n","    workspace = master_workspace, \n","    lakehouse = lakehouse,\n","    table_properties=sslh_config.to_dict(),\n","    table_generator=perf_lab.provision_sales_tables,\n","    capacity = capacity_id\n",") "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ad366812-f929-4f4c-9669-36fa178d8a4c"},{"cell_type":"code","source":["(master_dataset_name, master_dataset_id) = perf_lab.provision_semantic_model(\n","    workspace = master_workspace_id, \n","    lakehouse=lakehouse_id, \n","    semantic_model_name = master_dataset,\n","    semantic_model_mode = \"OneLake\",\n","    overwrite = True,\n","    metadata_generator = perf_lab.apply_sales_metadata,\n","    )\n","\n","print((master_dataset_name, master_dataset_id))"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cac7b781-890c-4dec-8f90-a49c3d5deedb"},{"cell_type":"markdown","source":["### Provision test semantic models\n","Creating numerous semantic models for testing can easily be accomplished by passing a test suite instance with the test definitions to the provision_test_semantic_models() function. For every unique combination of 'MasterWorkspace', 'MasterDataset', 'TargetWorkspace', and 'TargetDataset', this function creates the necessary semantic model clones that the test cycle later uses to run DAX queries."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4099e064-dbbc-43f6-a996-385105b2ea46"},{"cell_type":"code","source":["# Start with a test suite to supply the master and target dataset, workspace information.\n","test_suite = perf_lab.TestSuite(\n","    [\n","    perf_lab.TestDefinition(QueryId=\"TestQuery\", QueryText=\"EVALUATE SUMMARIZECOLUMNS(\\\"Test\\\", \\\"Hello World\\\")\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                TargetWorkspace=test_workspace, TargetDataset=test_dataset_A, DatasourceName=lakehouse,\n","                DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","    ])\n","\n","# Provision the test models by cloning the master semantic models\n","# in the specified test workspaces according to the test definitions.\n","perf_lab.provision_test_semantic_models( \n","    test_suite = test_suite,\n","    capacity = capacity_id,\n","    refresh_clones = True,\n","    )"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"785c4893-e06b-4f06-bb43-bb91c0b93236"},{"cell_type":"markdown","source":["### Refresh and warm up the test models\n","Before updating Delta tables and refreshing Direct Lake models, it is a good idea to simulate semantic models that are currently in use by running all the test queries without tracing. This brings the test semantic models into warm state."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2ec653e5-8a59-4aea-a9d7-9d22ddfca734"},{"cell_type":"code","source":["# Execute all queries in the test suite against their test models\n","# so that all relevant column data is loaded into memory.\n","test_suite = perf_lab.TestSuite(\n","    [\n","    perf_lab.TestDefinition(QueryId=\"TestQuery\", QueryText=\"EVALUATE SUMMARIZECOLUMNS(\\\"Test\\\", \\\"Hello World\\\")\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                TargetWorkspace=test_workspace, TargetDataset=test_dataset_A, DatasourceName=lakehouse,\n","                DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","    ])\n","\n","perf_lab.refresh_test_models(\n","    test_suite = test_suite,\n","    refresh_type = 'clearValuesFull'\n",") \n","\n","perf_lab.warmup_test_models(\n","    test_suite = test_suite\n",") "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"94be2668-2286-46dd-a996-8f1f26fa0035"},{"cell_type":"markdown","source":["### Analyze Delta tables and semantic model tables\n","To investigate the dependencies and interactions between Delta tables and Direct Lake models in various configurations, the perf lab includes functions to analyze the column segments for each table in the semantic model as well as the parquet files, storage groups, and other information for the Delta tables."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2da6fa5e-f9d2-4e09-a68c-ec51ee93accb"},{"cell_type":"code","source":["test_suite = perf_lab.TestSuite(\n","    [\n","    perf_lab.TestDefinition(QueryId=\"TestQuery\", QueryText=\"EVALUATE SUMMARIZECOLUMNS(\\\"Test\\\", \\\"Hello World\\\")\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                TargetWorkspace=test_workspace, TargetDataset=test_dataset_A, DatasourceName=lakehouse,\n","                DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","    ])\n","\n","test_suite = perf_lab.initialize_test_cycle(\n","    test_suite = test_suite, \n","    test_description = \"This run is for test purposes.\"\n","    )\n","\n","table_info = perf_lab.get_source_tables(\n","    test_suite = test_suite\n","    )\n","\n","display(table_info)\n","\n","column_segments = perf_lab.get_storage_table_column_segments(\n","    test_suite = test_suite,\n","    tables_info = table_info\n","    )\n","\n","display(column_segments)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"df073c47-0cdc-4b25-94d7-eb9744776776"},{"cell_type":"markdown","source":["### Simulate Lakehouse ETL\n","The perf lab has no real ETL pipeline and must therefore rely on a simulated ETL process. The perf lab accomplishes the work with the help of a sample callback function. Refer to the source code if you want to implement your own table update logic."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"36e7ef74-4e99-4e41-a26e-f699a612df56"},{"cell_type":"code","source":["# To update Delta tables, determine the list of Delta tables that must be processed. \n","test_suite = perf_lab.TestSuite(\n","    [\n","    perf_lab.TestDefinition(QueryId=\"TestQuery\", QueryText=\"EVALUATE SUMMARIZECOLUMNS(\\\"Test\\\", \\\"Hello World\\\")\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                TargetWorkspace=test_workspace, TargetDataset=test_dataset_A, DatasourceName=lakehouse,\n","                DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","    ])\n","\n","test_suite = perf_lab.initialize_test_cycle(\n","    test_suite = test_suite, \n","    test_description = \"This run is for test purposes.\"\n","    )\n","\n","table_info = perf_lab.get_source_tables(\n","    test_suite = test_suite\n","    )\n","\n","# Use the sample _filter_by_prefix() callback function \n","# to perform a rolling window update by deleting the oldest DateID\n","# and reinserting it as the newest DateID.\n","# The _filter_by_prefix() callback function expects a property bag\n","# that identifies the DateID column as the key column.\n","perf_lab.simulate_etl(\n","    source_tables_info = table_info,\n","    update_properties = {\"key_column\": \"name\", \"Optimize\": True},\n","    update_function = perf_lab.delete_reinsert_rows\n",")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3c9a91d8-ab03-4dcb-bb7a-f1a56ef14f43"},{"cell_type":"markdown","source":["### Deprovision perf lab resources\n","The perf lab also provides functions to clean up provisioned resources. However, the perf lab does not delete workspaces to avoid accidental data loss if an existing workspace with unrelated items was used in the perf lab. Note that deprovisioning lakehouses listed in the test definitions does indeed remove these lakehouses with all their tables. Make sure these lakehouses only contain perf lab tables or delete the resources manually."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"739a8fdb-674b-4268-ab41-4e6bb9a5154a"},{"cell_type":"code","source":["test_suite = perf_lab.TestSuite(\n","    [\n","    perf_lab.TestDefinition(QueryId=\"TestQuery\", QueryText=\"EVALUATE SUMMARIZECOLUMNS(\\\"Test\\\", \\\"Hello World\\\")\", MasterWorkspace=master_workspace, MasterDataset=master_dataset,\n","                TargetWorkspace=test_workspace, TargetDataset=test_dataset_A, DatasourceName=lakehouse,\n","                DatasourceWorkspace=master_workspace, DatasourceType=\"Lakehouse\")\n","    ])\n","\n","perf_lab.deprovision_semantic_models(\n","    test_suite = test_suite,\n","    delete_masters = True\n","    )\n","\n","# Delete the lakehouses listed in the test definitions.\n","\n","perf_lab.deprovision_lakehouses(\n","    test_suite = test_suite\n","    )"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"667befe1-f820-48a4-bbc7-716476d44a16"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"synapse_widget":{"state":{},"version":"0.1"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}